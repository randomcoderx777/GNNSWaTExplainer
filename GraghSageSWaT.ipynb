{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CUDA 可用性測試 ===\n",
      "PyTorch版本: 2.4.1+cu124\n",
      "CUDA是否可用: True\n",
      "CUDA版本: 12.4\n",
      "當前CUDA設備: 0\n",
      "設備名稱: NVIDIA GeForce RTX 2060\n",
      "設備數量: 1\n",
      "設備屬性: _CudaDeviceProperties(name='NVIDIA GeForce RTX 2060', major=7, minor=5, total_memory=6143MB, multi_processor_count=30)\n",
      "\n",
      "=== 矩陣乘法性能測試 (大小: 1000x1000) ===\n",
      "CPU平均時間: 0.0054 秒\n",
      "GPU平均時間: 0.0032 秒\n",
      "GPU加速比: 1.69x\n"
     ]
    }
   ],
   "source": [
    "from cuda_test import test_cuda_availability, matrix_multiplication_test\n",
    "test_cuda_availability()\n",
    "matrix_multiplication_test(size=1000, runs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dinosaur\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch_geometric.data import Data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SWaTGraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers=2):\n",
    "        super(SWaTGraphSAGE, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.convs = nn.ModuleList()\n",
    "        self.convs.append(SAGEConv(in_channels, hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(SAGEConv(hidden_channels, hidden_channels))\n",
    "        self.convs.append(SAGEConv(hidden_channels, out_channels))\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        for i in range(self.num_layers - 1):\n",
    "            x = self.convs[i](x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = self.dropout(x)\n",
    "            x = self.convs[-1](x, edge_index)\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_swat_graph(normal_df, attack_df=None, save_path='graph_data.pt'):\n",
    "    \"\"\"創建 SWaT 系統的圖結構\"\"\"\n",
    "    # 清理列名中的空格\n",
    "    normal_df.columns = normal_df.columns.str.strip()\n",
    "    if attack_df is not None:\n",
    "        attack_df.columns = attack_df.columns.str.strip()\n",
    "    \n",
    "    # 獲取特徵列\n",
    "    feature_cols = [col for col in normal_df.columns \n",
    "                   if col not in ['Timestamp', 'Normal/Attack']]\n",
    "    \n",
    "    print(\"\\n清理後的正常數據列名:\")\n",
    "    print(normal_df.columns.tolist())\n",
    "    print(\"\\n清理後的攻擊數據列名:\")\n",
    "    print(attack_df.columns.tolist() if attack_df is not None else \"None\")\n",
    "    \n",
    "    # 準備節點特徵\n",
    "    node_features = normal_df[feature_cols].values\n",
    "    if attack_df is not None:\n",
    "        attack_features = attack_df[feature_cols].values\n",
    "        node_features = np.vstack([node_features, attack_features])\n",
    "    \n",
    "    # 創建邊的連接關係\n",
    "    edges = []\n",
    "    feature_to_idx = {name: idx for idx, name in enumerate(feature_cols)}\n",
    "    \n",
    "    # 定義要連接的特徵對\n",
    "    connections = [\n",
    "    # P1 connections\n",
    "    ('FIT101', 'LIT101'),\n",
    "    ('MV101', 'FIT101'),\n",
    "    ('P101', 'LIT101'),\n",
    "    ('P102', 'FIT101'),\n",
    "\n",
    "    # P2 connections\n",
    "    ('AIT201', 'AIT202'),\n",
    "    ('AIT202', 'AIT203'),\n",
    "    ('FIT201', 'AIT201'),\n",
    "    ('MV201', 'FIT201'),\n",
    "    ('P201', 'FIT201'),\n",
    "    ('P202', 'AIT202'),\n",
    "    ('P203', 'AIT203'),\n",
    "    ('P204', 'FIT201'),\n",
    "    ('P205', 'AIT202'), \n",
    "    ('P206', 'AIT203'),  \n",
    "\n",
    "    # P3 connections\n",
    "    ('DPIT301', 'FIT301'),\n",
    "    ('FIT301', 'LIT301'),\n",
    "    ('MV301', 'FIT301'),\n",
    "    ('MV302', 'LIT301'),\n",
    "    ('MV303', 'FIT301'),\n",
    "    ('MV304', 'LIT301'),\n",
    "    ('P301', 'FIT301'),\n",
    "    ('P302', 'LIT301'),\n",
    "\n",
    "    # P4 connections\n",
    "    ('AIT401', 'AIT402'),\n",
    "    ('FIT401', 'LIT401'),\n",
    "    ('P401', 'FIT401'),\n",
    "    ('P402', 'LIT401'),\n",
    "    ('P403', 'FIT401'),\n",
    "    ('P404', 'LIT401'),\n",
    "    ('UV401', 'FIT401'),\n",
    "\n",
    "    # P5 connections\n",
    "    ('AIT501', 'AIT502'),\n",
    "    ('AIT502', 'AIT503'),\n",
    "    ('AIT503', 'AIT504'),\n",
    "    ('FIT501', 'AIT501'),\n",
    "    ('FIT502', 'AIT502'),\n",
    "    ('FIT503', 'AIT503'),\n",
    "    ('FIT504', 'AIT504'),\n",
    "    ('P501', 'FIT501'),\n",
    "    ('P502', 'FIT502'),\n",
    "    ('PIT501', 'FIT503'),\n",
    "    ('PIT502', 'FIT504'),\n",
    "    ('PIT503', 'FIT503'),\n",
    "\n",
    "    # P6 connections\n",
    "    ('FIT601', 'P601'),\n",
    "    ('P601', 'P602'),\n",
    "    ('P602', 'P603'),\n",
    "\n",
    "    # Cross-process connections\n",
    "    ('LIT101', 'AIT201'),  \n",
    "    ('AIT203', 'DPIT301'),\n",
    "    ('LIT301', 'AIT401'), \n",
    "    ('FIT401', 'AIT501'), \n",
    "    ('AIT503', 'FIT601'),  \n",
    "    ('LIT301', 'FIT201'),  \n",
    "    ('AIT401', 'DPIT301'), \n",
    "    ('FIT503', 'AIT401'), \n",
    "    ('P205', 'LIT301'),    \n",
    "    ('P206', 'FIT503')     \n",
    "    ]\n",
    "    \n",
    "    print(\"\\n創建的連接:\")\n",
    "    for src, dst in connections:\n",
    "        if src in feature_to_idx and dst in feature_to_idx:\n",
    "            i, j = feature_to_idx[src], feature_to_idx[dst]\n",
    "            edges.extend([[i, j], [j, i]])  # 添加雙向邊\n",
    "            print(f\"{src} <-> {dst}\")\n",
    "    \n",
    "    # 轉換為PyTorch張量\n",
    "    edge_index = torch.tensor(edges, dtype=torch.long).t()\n",
    "    x = torch.tensor(node_features, dtype=torch.float)\n",
    "    \n",
    "    # 創建標籤\n",
    "    y = torch.zeros(len(node_features))\n",
    "    if attack_df is not None:\n",
    "        y[len(normal_df):] = 1\n",
    "    \n",
    "    # 儲存 x 和 edge_index\n",
    "    torch.save({'x': x, 'edge_index': edge_index}, save_path)\n",
    "    print(f\"x 和 edge_index 已儲存至 {save_path}\")\n",
    "    \n",
    "    print(f\"\\n最終圖結構:\")\n",
    "    print(f\"節點數量: {x.size(0)}\")\n",
    "    print(f\"節點特徵維度: {x.size(1)}\")\n",
    "    print(f\"邊的數量: {edge_index.size(1)}\")\n",
    "    \n",
    "    return Data(x=x, edge_index=edge_index, y=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # connections = [\n",
    "    #     ('FIT101', 'LIT101'),  # P1 connections\n",
    "    #     ('MV101', 'FIT101'),\n",
    "    #     ('P101', 'LIT101'),\n",
    "    #     ('P102', 'FIT101'),\n",
    "        \n",
    "    #     ('AIT201', 'AIT202'),  # P2 connections\n",
    "    #     ('AIT202', 'AIT203'),\n",
    "    #     ('FIT201', 'AIT201'),\n",
    "        \n",
    "    #     ('DPIT301', 'FIT301'),  # P3 connections\n",
    "    #     ('FIT301', 'LIT301'),\n",
    "    #     ('MV301', 'FIT301'),\n",
    "    #     ('MV302', 'LIT301'),\n",
    "        \n",
    "    #     ('AIT401', 'AIT402'),  # P4 connections\n",
    "    #     ('FIT401', 'LIT401'),\n",
    "    #     ('P401', 'FIT401'),\n",
    "        \n",
    "    #     ('AIT501', 'AIT502'),  # P5 connections\n",
    "    #     ('AIT502', 'AIT503'),\n",
    "    #     ('FIT501', 'AIT501'),\n",
    "    #     ('FIT502', 'AIT502'),\n",
    "    #     ('FIT503', 'AIT503'),\n",
    "        \n",
    "    #     # Cross-process connections\n",
    "    #     ('LIT101', 'AIT201'),\n",
    "    #     ('AIT203', 'DPIT301'),\n",
    "    #     ('LIT301', 'AIT401'),\n",
    "    #     ('FIT401', 'AIT501')\n",
    "    # ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_graphsage(model, data, epochs=100, lr=0.01):\n",
    "    \"\"\"訓練 GraphSAGE 模型\"\"\"\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = torch.nn.BCELoss()\n",
    "    \n",
    "    # 分割訓練集和測試集\n",
    "    num_nodes = data.x.size(0)\n",
    "    train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "    test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "    \n",
    "    train_indices = np.random.choice(num_nodes, int(0.8 * num_nodes), replace=False)\n",
    "    train_mask[train_indices] = True\n",
    "    test_mask[~train_mask] = True\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        out = model(data.x, data.edge_index)\n",
    "        loss = criterion(out[train_mask].squeeze(), data.y[train_mask])\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                pred = (out[test_mask] > 0.5).float()\n",
    "                acc = (pred.squeeze() == data.y[test_mask]).float().mean()\n",
    "                print(f'Epoch {epoch+1:03d}, Loss: {loss:.4f}, Test Acc: {acc:.4f}')\n",
    "            model.train()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, data):\n",
    "    \"\"\"評估模型性能\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data.x, data.edge_index)\n",
    "        pred = (out > 0.5).float()\n",
    "        acc = (pred.squeeze() == data.y).float().mean()\n",
    "        \n",
    "        tp = ((pred.squeeze() == 1) & (data.y == 1)).sum()\n",
    "        fp = ((pred.squeeze() == 1) & (data.y == 0)).sum()\n",
    "        tn = ((pred.squeeze() == 0) & (data.y == 0)).sum()\n",
    "        fn = ((pred.squeeze() == 0) & (data.y == 1)).sum()\n",
    "        \n",
    "        precision = tp / (tp + fp)\n",
    "        recall = tp / (tp + fn)\n",
    "        f1 = 2 * precision * recall / (precision + recall)\n",
    "        \n",
    "    return {\n",
    "        'accuracy': acc.item(),\n",
    "        'precision': precision.item(),\n",
    "        'recall': recall.item(),\n",
    "        'f1': f1.item()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "開始載入數據...\n",
      "載入完成! 正常數據形狀: (495000, 53), 攻擊數據形狀: (449919, 53)\n",
      "\n",
      "創建圖結構...\n",
      "\n",
      "清理後的正常數據列名:\n",
      "['Timestamp', 'FIT101', 'LIT101', 'MV101', 'P101', 'P102', 'AIT201', 'AIT202', 'AIT203', 'FIT201', 'MV201', 'P201', 'P202', 'P203', 'P204', 'P205', 'P206', 'DPIT301', 'FIT301', 'LIT301', 'MV301', 'MV302', 'MV303', 'MV304', 'P301', 'P302', 'AIT401', 'AIT402', 'FIT401', 'LIT401', 'P401', 'P402', 'P403', 'P404', 'UV401', 'AIT501', 'AIT502', 'AIT503', 'AIT504', 'FIT501', 'FIT502', 'FIT503', 'FIT504', 'P501', 'P502', 'PIT501', 'PIT502', 'PIT503', 'FIT601', 'P601', 'P602', 'P603', 'Normal/Attack']\n",
      "\n",
      "清理後的攻擊數據列名:\n",
      "['Timestamp', 'FIT101', 'LIT101', 'MV101', 'P101', 'P102', 'AIT201', 'AIT202', 'AIT203', 'FIT201', 'MV201', 'P201', 'P202', 'P203', 'P204', 'P205', 'P206', 'DPIT301', 'FIT301', 'LIT301', 'MV301', 'MV302', 'MV303', 'MV304', 'P301', 'P302', 'AIT401', 'AIT402', 'FIT401', 'LIT401', 'P401', 'P402', 'P403', 'P404', 'UV401', 'AIT501', 'AIT502', 'AIT503', 'AIT504', 'FIT501', 'FIT502', 'FIT503', 'FIT504', 'P501', 'P502', 'PIT501', 'PIT502', 'PIT503', 'FIT601', 'P601', 'P602', 'P603', 'Normal/Attack']\n",
      "\n",
      "創建的連接:\n",
      "FIT101 <-> LIT101\n",
      "MV101 <-> FIT101\n",
      "P101 <-> LIT101\n",
      "P102 <-> FIT101\n",
      "AIT201 <-> AIT202\n",
      "AIT202 <-> AIT203\n",
      "FIT201 <-> AIT201\n",
      "MV201 <-> FIT201\n",
      "P201 <-> FIT201\n",
      "P202 <-> AIT202\n",
      "P203 <-> AIT203\n",
      "P204 <-> FIT201\n",
      "P205 <-> AIT202\n",
      "P206 <-> AIT203\n",
      "DPIT301 <-> FIT301\n",
      "FIT301 <-> LIT301\n",
      "MV301 <-> FIT301\n",
      "MV302 <-> LIT301\n",
      "MV303 <-> FIT301\n",
      "MV304 <-> LIT301\n",
      "P301 <-> FIT301\n",
      "P302 <-> LIT301\n",
      "AIT401 <-> AIT402\n",
      "FIT401 <-> LIT401\n",
      "P401 <-> FIT401\n",
      "P402 <-> LIT401\n",
      "P403 <-> FIT401\n",
      "P404 <-> LIT401\n",
      "UV401 <-> FIT401\n",
      "AIT501 <-> AIT502\n",
      "AIT502 <-> AIT503\n",
      "AIT503 <-> AIT504\n",
      "FIT501 <-> AIT501\n",
      "FIT502 <-> AIT502\n",
      "FIT503 <-> AIT503\n",
      "FIT504 <-> AIT504\n",
      "P501 <-> FIT501\n",
      "P502 <-> FIT502\n",
      "PIT501 <-> FIT503\n",
      "PIT502 <-> FIT504\n",
      "PIT503 <-> FIT503\n",
      "FIT601 <-> P601\n",
      "P601 <-> P602\n",
      "P602 <-> P603\n",
      "LIT101 <-> AIT201\n",
      "AIT203 <-> DPIT301\n",
      "LIT301 <-> AIT401\n",
      "FIT401 <-> AIT501\n",
      "AIT503 <-> FIT601\n",
      "LIT301 <-> FIT201\n",
      "AIT401 <-> DPIT301\n",
      "FIT503 <-> AIT401\n",
      "P205 <-> LIT301\n",
      "P206 <-> FIT503\n",
      "x 和 edge_index 已儲存至 graph_data.pt\n",
      "\n",
      "最終圖結構:\n",
      "節點數量: 944919\n",
      "節點特徵維度: 51\n",
      "邊的數量: 108\n",
      "圖創建完成! 節點數: 944919, 特徵維度: 51\n",
      "邊的數量: 108\n",
      "\n",
      "模型配置:\n",
      "輸入特徵維度: 51\n",
      "隱藏層維度: 64\n",
      "輸出維度: 1\n",
      "\n",
      "初始化模型...\n",
      "模型架構:\n",
      "SWaTGraphSAGE(\n",
      "  (convs): ModuleList(\n",
      "    (0): SAGEConv(51, 64, aggr=mean)\n",
      "    (1): SAGEConv(64, 1, aggr=mean)\n",
      "  )\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n",
      "\n",
      "開始訓練...\n",
      "Epoch 010, Loss: 0.4341, Test Acc: 0.9705\n",
      "Epoch 020, Loss: 0.1193, Test Acc: 0.9903\n",
      "Epoch 030, Loss: 0.0343, Test Acc: 0.9932\n",
      "Epoch 040, Loss: 0.0175, Test Acc: 0.9953\n",
      "Epoch 050, Loss: 0.0115, Test Acc: 0.9965\n",
      "Epoch 060, Loss: 0.0084, Test Acc: 0.9978\n",
      "Epoch 070, Loss: 0.0065, Test Acc: 0.9983\n",
      "Epoch 080, Loss: 0.0053, Test Acc: 0.9988\n",
      "Epoch 090, Loss: 0.0044, Test Acc: 0.9990\n",
      "Epoch 100, Loss: 0.0038, Test Acc: 0.9992\n",
      "訓練完成!\n",
      "\n",
      "進行模型評估...\n",
      "\n",
      "Model Performance:\n",
      "accuracy: 0.9996\n",
      "precision: 0.9998\n",
      "recall: 0.9993\n",
      "f1: 0.9995\n",
      "\n",
      "保存模型...\n",
      "模型已保存至 swat_graphsage_model.pt\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # 設定隨機種子確保結果可重現\n",
    "    torch.manual_seed(42)\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    print(\"開始載入數據...\")\n",
    "    # 讀取預處理後的數據\n",
    "    normal_df = pd.read_csv('processed_data/SWaT_normal.csv')\n",
    "    attack_df = pd.read_csv('processed_data/SWaT_attack.csv')\n",
    "    print(f\"載入完成! 正常數據形狀: {normal_df.shape}, 攻擊數據形狀: {attack_df.shape}\")\n",
    "    \n",
    "    print(\"\\n創建圖結構...\")\n",
    "    # 創建圖\n",
    "    data = create_swat_graph(normal_df, attack_df)\n",
    "    print(f\"圖創建完成! 節點數: {data.x.size(0)}, 特徵維度: {data.x.size(1)}\")\n",
    "    print(f\"邊的數量: {data.edge_index.size(1)}\")\n",
    "    \n",
    "    # 設置模型參數\n",
    "    in_channels = data.x.size(1)  # 特徵維度\n",
    "    hidden_channels = 64\n",
    "    out_channels = 1\n",
    "    print(f\"\\n模型配置:\")\n",
    "    print(f\"輸入特徵維度: {in_channels}\")\n",
    "    print(f\"隱藏層維度: {hidden_channels}\")\n",
    "    print(f\"輸出維度: {out_channels}\")\n",
    "    \n",
    "    print(\"\\n初始化模型...\")\n",
    "    # 創建模型\n",
    "    model = SWaTGraphSAGE(in_channels, hidden_channels, out_channels)\n",
    "    print(\"模型架構:\")\n",
    "    print(model)\n",
    "    \n",
    "    print(\"\\n開始訓練...\")\n",
    "    # 訓練模型\n",
    "    model = train_graphsage(model, data, epochs=100)\n",
    "    print(\"訓練完成!\")\n",
    "    \n",
    "    print(\"\\n進行模型評估...\")\n",
    "    # 評估模型\n",
    "    metrics = evaluate_model(model, data)\n",
    "    print(\"\\nModel Performance:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "    \n",
    "    # 保存模型\n",
    "    print(\"\\n保存模型...\")\n",
    "    torch.save({'model_state_dict': model.state_dict(),'x': data.x,'edge_index':  data.edge_index}, 'swat_graphsage_model.pt')      # 保存為新的文件\n",
    "    #torch.save(model.state_dict(), 'swat_graphsage_model.pt')\n",
    "    print(\"模型已保存至 swat_graphsage_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 詳細準確率分析 ===\n",
      "\n",
      "整體準確率: 0.9996\n",
      "正常數據準確率: 0.9999\n",
      "攻擊數據準確率: 0.9993\n",
      "\n",
      "混淆矩陣指標:\n",
      "真陽性 (True Positives): 449582\n",
      "真陰性 (True Negatives): 494929\n",
      "假陽性 (False Positives): 71\n",
      "假陰性 (False Negatives): 337\n",
      "\n",
      "其他性能指標:\n",
      "精確率 (Precision): 0.9998\n",
      "召回率 (Recall): 0.9993\n",
      "F1分數: 0.9995\n",
      "\n",
      "異常檢測結果分析:\n",
      "檢測到的異常比例: 0.4759\n",
      "最高異常分數: 1.0000\n",
      "最低異常分數: 0.0000\n",
      "平均異常分數: 0.4759\n",
      "\n",
      "不同閾值下的準確率:\n",
      "閾值 0.3: 0.9991\n",
      "閾值 0.4: 0.9995\n",
      "閾值 0.5: 0.9996\n",
      "閾值 0.6: 0.9995\n",
      "閾值 0.7: 0.9994\n"
     ]
    }
   ],
   "source": [
    "# 詳細的準確率分析\n",
    "print(\"\\n=== 詳細準確率分析 ===\")\n",
    "with torch.no_grad():\n",
    "    # 獲取預測結果\n",
    "    predictions = model(data.x, data.edge_index)\n",
    "    pred_labels = (predictions > 0.5).float().numpy().flatten()\n",
    "    true_labels = data.y.numpy()\n",
    "    \n",
    "    # 計算整體準確率\n",
    "    accuracy = (pred_labels == true_labels).mean()\n",
    "    print(f\"\\n整體準確率: {accuracy:.4f}\")\n",
    "    \n",
    "    # 計算每類的準確率\n",
    "    normal_mask = (true_labels == 0)\n",
    "    attack_mask = (true_labels == 1)\n",
    "    \n",
    "    normal_accuracy = (pred_labels[normal_mask] == true_labels[normal_mask]).mean()\n",
    "    attack_accuracy = (pred_labels[attack_mask] == true_labels[attack_mask]).mean()\n",
    "    \n",
    "    print(f\"正常數據準確率: {normal_accuracy:.4f}\")\n",
    "    print(f\"攻擊數據準確率: {attack_accuracy:.4f}\")\n",
    "    \n",
    "    # 計算混淆矩陣指標\n",
    "    tp = np.sum((pred_labels == 1) & (true_labels == 1))\n",
    "    tn = np.sum((pred_labels == 0) & (true_labels == 0))\n",
    "    fp = np.sum((pred_labels == 1) & (true_labels == 0))\n",
    "    fn = np.sum((pred_labels == 0) & (true_labels == 1))\n",
    "    \n",
    "    print(\"\\n混淆矩陣指標:\")\n",
    "    print(f\"真陽性 (True Positives): {tp}\")\n",
    "    print(f\"真陰性 (True Negatives): {tn}\")\n",
    "    print(f\"假陽性 (False Positives): {fp}\")\n",
    "    print(f\"假陰性 (False Negatives): {fn}\")\n",
    "    \n",
    "    # 計算精確率、召回率和F1分數\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    print(\"\\n其他性能指標:\")\n",
    "    print(f\"精確率 (Precision): {precision:.4f}\")\n",
    "    print(f\"召回率 (Recall): {recall:.4f}\")\n",
    "    print(f\"F1分數: {f1:.4f}\")\n",
    "    \n",
    "    # 異常檢測結果分析\n",
    "    print(\"\\n異常檢測結果分析:\")\n",
    "    anomaly_scores = predictions.numpy().flatten()\n",
    "    \n",
    "    print(f\"檢測到的異常比例: {(anomaly_scores > 0.5).mean():.4f}\")\n",
    "    print(f\"最高異常分數: {anomaly_scores.max():.4f}\")\n",
    "    print(f\"最低異常分數: {anomaly_scores.min():.4f}\")\n",
    "    print(f\"平均異常分數: {anomaly_scores.mean():.4f}\")\n",
    "    \n",
    "    # 計算不同閾值下的準確率\n",
    "    print(\"\\n不同閾值下的準確率:\")\n",
    "    thresholds = [0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "    for threshold in thresholds:\n",
    "        pred_at_threshold = (anomaly_scores > threshold).astype(float)\n",
    "        acc_at_threshold = (pred_at_threshold == true_labels).mean()\n",
    "        print(f\"閾值 {threshold}: {acc_at_threshold:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_feature_importance(model, data, feature_names):\n",
    "    \"\"\"分析特徵重要性和節點關係\"\"\"\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    \n",
    "    # 1. 計算特徵重要性\n",
    "    with torch.no_grad():\n",
    "        feature_importance = []\n",
    "        base_output = model(data.x, data.edge_index)\n",
    "        base_pred = (base_output > 0.5).float()\n",
    "        \n",
    "        for i in range(data.x.size(1)):\n",
    "            perturbed_x = data.x.clone()\n",
    "            perturbed_x[:, i] = torch.zeros_like(perturbed_x[:, i])\n",
    "            \n",
    "            new_output = model(perturbed_x, data.edge_index)\n",
    "            new_pred = (new_output > 0.5).float()\n",
    "            \n",
    "            importance = (base_pred != new_pred).float().mean().item()\n",
    "            feature_importance.append(importance)\n",
    "        \n",
    "        # 正規化特徵重要性\n",
    "        feature_importance = np.array(feature_importance)\n",
    "        feature_importance = (feature_importance - feature_importance.min()) / (feature_importance.max() - feature_importance.min())\n",
    "        \n",
    "        # 繪製熱力圖\n",
    "        plt.subplot(121)\n",
    "        importance_df = pd.DataFrame({\n",
    "            'Feature': feature_names,\n",
    "            'Importance': feature_importance\n",
    "        }).sort_values('Importance', ascending=True)\n",
    "        \n",
    "        sns.barplot(x='Importance', y='Feature', data=importance_df, \n",
    "                   palette='YlOrRd')\n",
    "        plt.title('Feature Importance')\n",
    "        plt.xlabel('Normalized Importance')\n",
    "        \n",
    "        # 繪製節點關係圖\n",
    "        plt.subplot(122)\n",
    "        G = nx.Graph()\n",
    "        \n",
    "        # 添加節點\n",
    "        for i, name in enumerate(feature_names):\n",
    "            G.add_node(i, name=name, importance=feature_importance[i])\n",
    "        \n",
    "        # 添加邊\n",
    "        edge_index = data.edge_index.numpy()\n",
    "        edges = list(zip(edge_index[0], edge_index[1]))\n",
    "        G.add_edges_from(edges)\n",
    "        \n",
    "        # 設置節點位置\n",
    "        pos = nx.spring_layout(G, k=1, iterations=50)\n",
    "        \n",
    "        # 繪製節點\n",
    "        node_sizes = [3000 * G.nodes[node]['importance'] for node in G.nodes()]\n",
    "        node_colors = [G.nodes[node]['importance'] for node in G.nodes()]\n",
    "        \n",
    "        nx.draw_networkx_nodes(G, pos, \n",
    "                             node_size=node_sizes,\n",
    "                             node_color=node_colors,\n",
    "                             cmap=plt.cm.YlOrRd)\n",
    "        nx.draw_networkx_edges(G, pos, alpha=0.2, edge_color='gray')\n",
    "        \n",
    "        # 添加標籤\n",
    "        labels = {i: f\"{name}\\n{feature_importance[i]:.2f}\" \n",
    "                 for i, name in enumerate(feature_names)}\n",
    "        nx.draw_networkx_labels(G, pos, labels, font_size=8)\n",
    "        \n",
    "        plt.title('Node Relationship Graph\\n(Node size and color indicate importance)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 打印重要性排名\n",
    "    importance_ranking = [(name, feature_importance[i]) \n",
    "                         for i, name in enumerate(feature_names)]\n",
    "    importance_ranking.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    print(\"\\n特徵重要性排名 (前10名):\")\n",
    "    for name, importance in importance_ranking[:10]:\n",
    "        print(f\"{name}: {importance:.4f}\")\n",
    "    \n",
    "    # 進程級別分析\n",
    "    process_importance = {}\n",
    "    for name, importance in importance_ranking:\n",
    "        process_num = name[-3:] if name[-3:].isdigit() else name[-2:] if name[-2:].isdigit() else name[-1]\n",
    "        process = f\"P{process_num}\"\n",
    "        if process not in process_importance:\n",
    "            process_importance[process] = []\n",
    "        process_importance[process].append(importance)\n",
    "    \n",
    "    print(\"\\n進程重要性排名:\")\n",
    "    process_avg_importance = {\n",
    "        process: np.mean(importances) \n",
    "        for process, importances in process_importance.items()\n",
    "    }\n",
    "    sorted_processes = sorted(\n",
    "        process_avg_importance.items(), \n",
    "        key=lambda x: x[1], \n",
    "        reverse=True\n",
    "    )\n",
    "    \n",
    "    for process, avg_importance in sorted_processes:\n",
    "        print(f\"{process}: {avg_importance:.4f}\")\n",
    "    \n",
    "    return importance_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_names(normal_df):\n",
    "    \"\"\"獲取特徵名稱\"\"\"\n",
    "    return [col for col in normal_df.columns \n",
    "            if col not in ['Timestamp', 'Normal/Attack']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "清理後的正常數據列名:\n",
      "['Timestamp', 'FIT101', 'LIT101', 'MV101', 'P101', 'P102', 'AIT201', 'AIT202', 'AIT203', 'FIT201', 'MV201', 'P201', 'P202', 'P203', 'P204', 'P205', 'P206', 'DPIT301', 'FIT301', 'LIT301', 'MV301', 'MV302', 'MV303', 'MV304', 'P301', 'P302', 'AIT401', 'AIT402', 'FIT401', 'LIT401', 'P401', 'P402', 'P403', 'P404', 'UV401', 'AIT501', 'AIT502', 'AIT503', 'AIT504', 'FIT501', 'FIT502', 'FIT503', 'FIT504', 'P501', 'P502', 'PIT501', 'PIT502', 'PIT503', 'FIT601', 'P601', 'P602', 'P603', 'Normal/Attack']\n",
      "\n",
      "清理後的攻擊數據列名:\n",
      "['Timestamp', 'FIT101', 'LIT101', 'MV101', 'P101', 'P102', 'AIT201', 'AIT202', 'AIT203', 'FIT201', 'MV201', 'P201', 'P202', 'P203', 'P204', 'P205', 'P206', 'DPIT301', 'FIT301', 'LIT301', 'MV301', 'MV302', 'MV303', 'MV304', 'P301', 'P302', 'AIT401', 'AIT402', 'FIT401', 'LIT401', 'P401', 'P402', 'P403', 'P404', 'UV401', 'AIT501', 'AIT502', 'AIT503', 'AIT504', 'FIT501', 'FIT502', 'FIT503', 'FIT504', 'P501', 'P502', 'PIT501', 'PIT502', 'PIT503', 'FIT601', 'P601', 'P602', 'P603', 'Normal/Attack']\n",
      "\n",
      "創建的連接:\n",
      "FIT101 <-> LIT101\n",
      "MV101 <-> FIT101\n",
      "P101 <-> LIT101\n",
      "P102 <-> FIT101\n",
      "AIT201 <-> AIT202\n",
      "AIT202 <-> AIT203\n",
      "FIT201 <-> AIT201\n",
      "MV201 <-> FIT201\n",
      "P201 <-> FIT201\n",
      "P202 <-> AIT202\n",
      "P203 <-> AIT203\n",
      "P204 <-> FIT201\n",
      "P205 <-> AIT202\n",
      "P206 <-> AIT203\n",
      "DPIT301 <-> FIT301\n",
      "FIT301 <-> LIT301\n",
      "MV301 <-> FIT301\n",
      "MV302 <-> LIT301\n",
      "MV303 <-> FIT301\n",
      "MV304 <-> LIT301\n",
      "P301 <-> FIT301\n",
      "P302 <-> LIT301\n",
      "AIT401 <-> AIT402\n",
      "FIT401 <-> LIT401\n",
      "P401 <-> FIT401\n",
      "P402 <-> LIT401\n",
      "P403 <-> FIT401\n",
      "P404 <-> LIT401\n",
      "UV401 <-> FIT401\n",
      "AIT501 <-> AIT502\n",
      "AIT502 <-> AIT503\n",
      "AIT503 <-> AIT504\n",
      "FIT501 <-> AIT501\n",
      "FIT502 <-> AIT502\n",
      "FIT503 <-> AIT503\n",
      "FIT504 <-> AIT504\n",
      "P501 <-> FIT501\n",
      "P502 <-> FIT502\n",
      "PIT501 <-> FIT503\n",
      "PIT502 <-> FIT504\n",
      "PIT503 <-> FIT503\n",
      "FIT601 <-> P601\n",
      "P601 <-> P602\n",
      "P602 <-> P603\n",
      "LIT101 <-> AIT201\n",
      "AIT203 <-> DPIT301\n",
      "LIT301 <-> AIT401\n",
      "FIT401 <-> AIT501\n",
      "AIT503 <-> FIT601\n",
      "LIT301 <-> FIT201\n",
      "AIT401 <-> DPIT301\n",
      "FIT503 <-> AIT401\n",
      "P205 <-> LIT301\n",
      "P206 <-> FIT503\n",
      "x 和 edge_index 已儲存至 graph_data.pt\n",
      "\n",
      "最終圖結構:\n",
      "節點數量: 944919\n",
      "節點特徵維度: 51\n",
      "邊的數量: 108\n",
      "分析特徵重要性...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dinosaur\\AppData\\Local\\Temp\\ipykernel_21060\\2583726908.py:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('swat_graphsage_model.pt')\n",
      "C:\\Users\\Dinosaur\\AppData\\Local\\Temp\\ipykernel_21060\\3587461903.py:32: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x='Importance', y='Feature', data=importance_df,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "特徵重要性排名 (前10名):\n",
      "AIT202: 1.0000\n",
      "AIT501: 0.3716\n",
      "DPIT301: 0.1933\n",
      "LIT301: 0.0970\n",
      "FIT201: 0.0899\n",
      "LIT101: 0.0460\n",
      "AIT502: 0.0459\n",
      "PIT502: 0.0390\n",
      "AIT402: 0.0360\n",
      "P501: 0.0359\n",
      "\n",
      "進程重要性排名:\n",
      "P202: 0.5000\n",
      "P501: 0.1030\n",
      "P301: 0.0600\n",
      "P201: 0.0248\n",
      "P304: 0.0225\n",
      "P502: 0.0217\n",
      "P402: 0.0200\n",
      "P101: 0.0160\n",
      "P504: 0.0155\n",
      "P205: 0.0146\n",
      "P302: 0.0139\n",
      "P503: 0.0114\n",
      "P401: 0.0105\n",
      "P303: 0.0068\n",
      "P203: 0.0064\n",
      "P403: 0.0006\n",
      "P601: 0.0000\n",
      "P102: 0.0000\n",
      "P204: 0.0000\n",
      "P206: 0.0000\n",
      "P404: 0.0000\n",
      "P602: 0.0000\n",
      "P603: 0.0000\n",
      "\n",
      "分析完成! 結果已保存至 feature_importance.png\n"
     ]
    }
   ],
   "source": [
    "normal_df = pd.read_csv('processed_data/normal.csv')\n",
    "attack_df = pd.read_csv('processed_data/attack.csv')\n",
    "\n",
    "# 獲取特徵名稱\n",
    "feature_names = get_feature_names(normal_df)\n",
    "\n",
    "# 創建圖數據\n",
    "data = create_swat_graph(normal_df, attack_df)\n",
    "\n",
    "# 載入模型\n",
    "model = SWaTGraphSAGE(\n",
    "    in_channels=data.x.size(1),\n",
    "    hidden_channels=64,\n",
    "    out_channels=1\n",
    ")\n",
    "checkpoint = torch.load('swat_graphsage_model.pt')\n",
    "\n",
    "# 恢復模型權重\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# model.load_state_dict(torch.load('swat_graphsage_model.pt'))\n",
    "model.eval()\n",
    "\n",
    "print(\"分析特徵重要性...\")\n",
    "importance_ranking = analyze_feature_importance(model, data, feature_names)\n",
    "\n",
    "print(\"\\n分析完成! 結果已保存至 feature_importance.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
